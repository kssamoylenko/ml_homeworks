{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1. Предварительная\n",
    "Предварительная обработка данных [2 балла]\n",
    "\n",
    "+ Удалите неоднозначные имена (те имена, которые являются и мужскими, и женскими дновременно), если такие есть;\n",
    "\n",
    "+ Создайте обучающее и тестовое множество так, чтобы в обучающем множестве классы были сбалансированы, т.е. к классу принадлежало бы одинаковое количество имен;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем наши файлы с именами, убираем из них совпадения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5001"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "male = open('male.txt', 'r')\n",
    "male = list(map(lambda x:x.strip(), male))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2943"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commons = set(male)&set(female) #смотрим количество имен, которые встречаются и в мужском, и в женском списке\n",
    "len(commons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_female = list(set(female)^set(commons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4635"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_male = list(set(male)^set(commons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2578"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем обучающее и тестовое множество: т.к. мужских имено меньше, деление типа \"тестовая выборка -- 0.3 от всего списка\" дало бы неравнозначные результаты. Поэтому делим по индексу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFem = clean_female[:1500]\n",
    "testFem = clean_female[1500:]\n",
    "\n",
    "trainMale = clean_male[:1500]\n",
    "testMale = clean_male[1500:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainFemdf = pd.DataFrame(trainFem) #объединяем фреймы с данными, присваиваем им классы\n",
    "trainFemdf['class'] = 1\n",
    "\n",
    "testFemdf = pd.DataFrame(testFem)\n",
    "testFemdf['class'] = 1\n",
    "\n",
    "trainMaledf = pd.DataFrame(trainMale)\n",
    "trainMaledf['class'] = 2\n",
    "\n",
    "testMaledf = pd.DataFrame(testMale)\n",
    "testMaledf['class'] = 2\n",
    "\n",
    "trainFemdf.columns = ['name', 'class']\n",
    "testFemdf.columns = ['name', 'class']\n",
    "trainMaledf.columns = ['name', 'class']\n",
    "testMaledf.columns = ['name', 'class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_train = [trainFemdf, trainMaledf]\n",
    "frames_test = [testFemdf, testMaledf]\n",
    "\n",
    "train = pd.concat(frames_train)\n",
    "test = pd.concat(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train[['name']] \n",
    "test_df = test[['name']]\n",
    "y_train = train[['class']] \n",
    "y_test = test[['class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_text(data):\n",
    "    clean_line = re.sub('[\\W\\d_-]+', ' ', data.lower().strip())\n",
    "    return re.sub(' +', ' ', clean_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.applymap(lower_text) #приводим все к нижнему регистру\n",
    "test_df = test_df.applymap(lower_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Часть 2. Базовая\n",
    "\n",
    "Базовый метод классификации [3 балла]\n",
    "\n",
    "Используйте метод наивного Байеса или логистическую регрессию для классификации имен: в качестве признаков используйте символьные $n$-граммы. Сравните результаты, получаемые при разных $n=2,3,4$ по $F$-мере и аккуратности. В каких случаях метод ошибается?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_char(name, b): #функция для разбиения слова на н-граммы: name - это имя, b - число символов\n",
    "    chargram = [name[i:i+b] for i in range(len(name)-b+1)]\n",
    "    return chargram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_char(names, b): # функция проходится по каждому имени в списке и возвращает список n-грамм\n",
    "    return [get_char(name, b) for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traingrams = list_char(train_df['name'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testgrams = list_char(test_df['name'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['gl', 'le', 'en', 'nn', 'ni', 'ie'],\n",
       " ['ca', 'at', 'tr', 'ri', 'in', 'na'],\n",
       " ['ce', 'es', 'sy', 'ya'],\n",
       " ['je', 'ea', 'an', 'nn', 'ni', 'in', 'ne'],\n",
       " ['ca', 'ac', 'ci', 'il', 'li', 'ie'],\n",
       " ['de', 'ev', 'vo', 'on', 'nn', 'ne'],\n",
       " ['na', 'an'],\n",
       " ['no', 'or', 'ra', 'ah'],\n",
       " ['do', 'or', 'ro'],\n",
       " ['je', 'es', 'ss', 'sy']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traingrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [\" \".join(tr) for tr in traingrams] #делаем список, где для каждого имени список н-грамм это строка\n",
    "X_test = [\" \".join(tr) for tr in testgrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gl le en nn ni ie',\n",
       " 'ca at tr ri in na',\n",
       " 'ce es sy ya',\n",
       " 'je ea an nn ni in ne',\n",
       " 'ca ac ci il li ie',\n",
       " 'de ev vo on nn ne',\n",
       " 'na an',\n",
       " 'no or ra ah',\n",
       " 'do or ro',\n",
       " 'je es ss sy']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_train_df.columns = ['name']\n",
    "X_test_df.columns = ['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Создаем векторное представление наших имен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import sys\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "def tfidf_vec(voc=None):\n",
    "    if(voc):\n",
    "        vectorizer = TfidfVectorizer()  \n",
    "        tr = vectorizer.fit_transform(X_train_df[\"name\"]) \n",
    "        te = vectorizer.fit_transform(X_test_df[\"name\"]) \n",
    "        return (tr, te)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer() \n",
    "        tr = vectorizer.fit_transform(X_train_df[\"name\"]) \n",
    "        voc = vectorizer.get_feature_names()\n",
    "        vectorizer = CountVectorizer(vocabulary=voc) \n",
    "        te = vectorizer.fit_transform(X_test_df[\"name\"]) \n",
    "        return (tr, te)\n",
    "train_counts, test_counts = tfidf_vec() \n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "x_train = tfidf_transformer.fit_transform(train_counts)\n",
    "x_test = tfidf_transformer.fit_transform(test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем байесовский классификатор на получившихся данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB \n",
    "clf = MultinomialNB().fit(x_train, y_train)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4213"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(x_test)\n",
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.81      0.84      3135\n",
      "          2       0.54      0.65      0.59      1078\n",
      "\n",
      "avg / total       0.79      0.77      0.77      4213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#cмотрим результаты\n",
    "print(classification_report(y_pred=predicted, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выглядит неплохо! Попробуем изменить значение n в изначальной функции и посмотрим, что изменится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traingrams = list_char(train_df['name'], 3)\n",
    "testgrams = list_char(test_df['name'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [\" \".join(tr) for tr in traingrams]\n",
    "X_test = [\" \".join(tr) for tr in testgrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gle len enn nni nie',\n",
       " 'cat atr tri rin ina',\n",
       " 'ces esy sya',\n",
       " 'jea ean ann nni nin ine',\n",
       " 'cac aci cil ili lie',\n",
       " 'dev evo von onn nne',\n",
       " 'nan',\n",
       " 'nor ora rah',\n",
       " 'dor oro',\n",
       " 'jes ess ssy']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_train_df.columns = ['name']\n",
    "X_test_df.columns = ['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "train_counts, test_counts = tfidf_vec() \n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "x_train = tfidf_transformer.fit_transform(train_counts)\n",
    "x_test = tfidf_transformer.fit_transform(test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.89      0.82      0.85      3135\n",
      "          2       0.57      0.71      0.63      1078\n",
      "\n",
      "avg / total       0.81      0.79      0.80      4213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(x_train, y_train)\n",
    "predicted = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred=predicted, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так стало немного лучше! Заметим, что женские имена в целом классификатор определяет лучше, чем мужские. А если попробовать 4-граммы?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fourtraingrams = list_char(train_df['name'], 4)\n",
    "fourtestgrams = list_char(test_df['name'], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [\" \".join(tr) for tr in fourtraingrams]\n",
    "X_test = [\" \".join(tr) for tr in fourtestgrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['glen lenn enni nnie',\n",
       " 'catr atri trin rina',\n",
       " 'cesy esya',\n",
       " 'jean eann anni nnin nine',\n",
       " 'caci acil cili ilie',\n",
       " 'devo evon vonn onne',\n",
       " '',\n",
       " 'nora orah',\n",
       " 'doro',\n",
       " 'jess essy']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_train_df.columns = ['name']\n",
    "X_test_df.columns = ['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "train_counts, test_counts = tfidf_vec() \n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "x_train = tfidf_transformer.fit_transform(train_counts)\n",
    "x_test = tfidf_transformer.fit_transform(test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.86      0.86      3135\n",
      "          2       0.59      0.60      0.60      1078\n",
      "\n",
      "avg / total       0.79      0.79      0.79      4213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(x_train, y_train)\n",
    "predicted = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_pred=predicted, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результативность изменилась, но незначительно. Для женских имен результативность выросла, а для мужских упала. Видимо, n-граммы длиной 3 являются оптимальными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Часть 3. Нейросетевая\n",
    "Используйте реккурентную нейронную сеть с LSTM для решения задачи. В ней может быть несколько слоев с LSTM, несколько слоев c Bidirectional(LSTM). У нейронной сети один выход, определяющий класс имени.\n",
    "\n",
    "Представление имени для классификации в этом случае: бинарная матрица размера (количество букв в алфавите $\\times$ максимальная длина имени). Обозначим его через $x$. Если первая буква имени a, то $x[1][1] = 1$, если вторая – b, то  $x[2][1] = 1$ – то есть, используется one hot encoding. Не забудьте, что все имена должны быть одной длины – maxlen. Это представление имени основано на векторной модели (BoW).\n",
    "\n",
    "Не забудьте про регуляризацию нейронной сети дропаутами.\n",
    "\n",
    "Сравните результаты baseline метода, полученные на предыдущем шаге, и результаты нейронной сети по F$-мере и аккуратности. Какой метод лучше и почему?\n",
    "\n",
    "Сравните результаты, получаемые при разных значениях дропаута, разных числах узлов на слоях нейронной сети по $F$-мере и аккуратности. В каких случаях нейронная сеть ошибается?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras import __version__ as keras_version\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим очищенные от совпадений списки имен к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_male = [m_name.lower() for m_name in clean_male]\n",
    "low_female = [f_name.lower() for f_name in clean_female]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names_count = len(low_male) + len(low_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самое длинное мужское имя: jean-christophe 15 символов\n"
     ]
    }
   ],
   "source": [
    "print('Самое длинное мужское имя:', max(low_male, key=len), len(max(low_male, key=len)), 'символов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самое длинное женское имя: helen-elizabeth 15 символов\n"
     ]
    }
   ],
   "source": [
    "print('Самое длинное женское имя:', max(low_female, key=len), len(max(low_female, key=len)), 'символов')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = len(max(low_female, key=len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем количество используемых символов, присваиваем им номера, создаем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = set(  \"\".join(low_male) + \"\".join(low_female))\n",
    "char_index = dict((c, i) for i, c in enumerate(chars))\n",
    "index_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'f',\n",
       " 1: 'k',\n",
       " 2: 'l',\n",
       " 3: 'e',\n",
       " 4: 's',\n",
       " 5: 'x',\n",
       " 6: 'n',\n",
       " 7: 'a',\n",
       " 8: 'o',\n",
       " 9: 'm',\n",
       " 10: 't',\n",
       " 11: '-',\n",
       " 12: 'p',\n",
       " 13: 'j',\n",
       " 14: 'z',\n",
       " 15: 'w',\n",
       " 16: 'y',\n",
       " 17: 'd',\n",
       " 18: 'q',\n",
       " 19: 'b',\n",
       " 20: 'v',\n",
       " 21: 'c',\n",
       " 22: \"'\",\n",
       " 23: 'g',\n",
       " 24: 'u',\n",
       " 25: 'h',\n",
       " 26: 'r',\n",
       " 27: ' ',\n",
       " 28: 'i'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем бинарную матрицу (пока что пустую) из кол-ва имен, используемых букв и максимальной длины имени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.zeros((3000, maxlen, len(chars)), dtype=np.bool)\n",
    "X_test = np.zeros((names_count-3000, maxlen, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((3000, 2 ), dtype=np.bool)\n",
    "y_test = np.zeros((names_count-3000, 2 ), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, name in enumerate(low_male): #\"кодируем\" имена, разбиваем на тестовую и обучающую выборки\n",
    "    for t, char in enumerate(name):\n",
    "        if i < 1500:\n",
    "            X_train[i, t, char_index[char]] = 1\n",
    "        else:\n",
    "            X_test[i-1500, t, char_index[char]] = 1\n",
    "    if i < 1500:\n",
    "        y_train[i, 0 ] = 1\n",
    "    else:\n",
    "        y_test[i-1500, 0] = 1\n",
    "\n",
    "for i, name in enumerate(low_female):\n",
    "    for t, char in enumerate(name):\n",
    "        if i < 1500:\n",
    "            X_train[i+1500, t, char_index[char]] = 1\n",
    "        else:\n",
    "            X_test[i-len(low_male)+1500, t, char_index[char]] = 1\n",
    "    if i < 1500:\n",
    "        y_train[i+1500, 1 ] = 1\n",
    "    else:\n",
    "        y_test[i-len(low_male)+1500, 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report, confusion_matrix\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Ksenia\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "2700/2700 [==============================] - 121s 45ms/step - loss: 0.6735 - acc: 0.6544 - val_loss: 0.7030 - val_acc: 0.4900\n",
      "Epoch 2/10\n",
      "2700/2700 [==============================] - 117s 43ms/step - loss: 0.5681 - acc: 0.7244 - val_loss: 0.6463 - val_acc: 0.6133\n",
      "Epoch 3/10\n",
      "2700/2700 [==============================] - 116s 43ms/step - loss: 0.5299 - acc: 0.7411 - val_loss: 0.5286 - val_acc: 0.7200\n",
      "Epoch 4/10\n",
      "2700/2700 [==============================] - 118s 44ms/step - loss: 0.5112 - acc: 0.7504 - val_loss: 0.9617 - val_acc: 0.4367\n",
      "Epoch 5/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.5006 - acc: 0.7567 - val_loss: 0.6741 - val_acc: 0.6500\n",
      "Epoch 6/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4902 - acc: 0.7637 - val_loss: 0.5683 - val_acc: 0.7033\n",
      "Epoch 7/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4692 - acc: 0.7826 - val_loss: 0.5578 - val_acc: 0.7267\n",
      "Epoch 8/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4582 - acc: 0.7870 - val_loss: 0.6463 - val_acc: 0.6233\n",
      "Epoch 9/10\n",
      "2700/2700 [==============================] - 120s 44ms/step - loss: 0.4388 - acc: 0.8037 - val_loss: 1.5949 - val_acc: 0.3767\n",
      "Epoch 10/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4270 - acc: 0.8033 - val_loss: 0.5494 - val_acc: 0.7367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a160aa908>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, validation_split=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4213/4213 [==============================] - 59s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test) #проверяем модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.7267938192457194\n",
      "Test accuracy: 0.6582008070258722\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_classes = preds.argmax(axis=-1)\n",
    "y_test_ar = y_test.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.74      0.68      1734\n",
      "          1       0.79      0.71      0.75      2479\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_classes, y_true=y_test_ar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Результаты получились несколько хуже, чем при обучении при помощи байесовского метода (там f-мера была 80). Попробуем изменить значение дропаута."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "2700/2700 [==============================] - 121s 45ms/step - loss: 0.6152 - acc: 0.6463 - val_loss: 0.4992 - val_acc: 0.7467\n",
      "Epoch 2/10\n",
      "2700/2700 [==============================] - 116s 43ms/step - loss: 0.5544 - acc: 0.7248 - val_loss: 0.9278 - val_acc: 0.4700\n",
      "Epoch 3/10\n",
      "2700/2700 [==============================] - 116s 43ms/step - loss: 0.5217 - acc: 0.7530 - val_loss: 0.5258 - val_acc: 0.7100\n",
      "Epoch 4/10\n",
      "2700/2700 [==============================] - 118s 44ms/step - loss: 0.5112 - acc: 0.7530 - val_loss: 0.5949 - val_acc: 0.6967\n",
      "Epoch 5/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4974 - acc: 0.7663 - val_loss: 0.5301 - val_acc: 0.7533\n",
      "Epoch 6/10\n",
      "2700/2700 [==============================] - 118s 44ms/step - loss: 0.4791 - acc: 0.7804 - val_loss: 0.7420 - val_acc: 0.5567\n",
      "Epoch 7/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4656 - acc: 0.7756 - val_loss: 0.5218 - val_acc: 0.7200\n",
      "Epoch 8/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4507 - acc: 0.7930 - val_loss: 0.4993 - val_acc: 0.7533\n",
      "Epoch 9/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4362 - acc: 0.8007 - val_loss: 0.6388 - val_acc: 0.7100\n",
      "Epoch 10/10\n",
      "2700/2700 [==============================] - 119s 44ms/step - loss: 0.4206 - acc: 0.8115 - val_loss: 0.6350 - val_acc: 0.6300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a259d7e80>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(512, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(LSTM(512, return_sequences=False))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Dense(2))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model2.fit(X_train, y_train, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4213/4213 [==============================] - 54s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.6998385692078514\n",
      "Test accuracy: 0.6280560170899596\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score2[0])\n",
    "print('Test accuracy:', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_classes = preds2.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.81      0.70      1734\n",
      "          1       0.83      0.65      0.73      2479\n",
      "\n",
      "avg / total       0.74      0.71      0.72      4213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_classes, y_true=y_test_ar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты незначительно изменились. Скорректируем количество узлов LSTM на модели со старами параметрами дропаута:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "2700/2700 [==============================] - 9s 3ms/step - loss: 0.6047 - acc: 0.6585 - val_loss: 0.8864 - val_acc: 0.4467\n",
      "Epoch 2/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.5214 - acc: 0.7441 - val_loss: 0.9465 - val_acc: 0.3833\n",
      "Epoch 3/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.5027 - acc: 0.7552 - val_loss: 0.5799 - val_acc: 0.6867\n",
      "Epoch 4/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4941 - acc: 0.7619 - val_loss: 0.6790 - val_acc: 0.6233\n",
      "Epoch 5/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4790 - acc: 0.7778 - val_loss: 0.5563 - val_acc: 0.7200\n",
      "Epoch 6/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4719 - acc: 0.7781 - val_loss: 0.7241 - val_acc: 0.5667\n",
      "Epoch 7/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4715 - acc: 0.7807 - val_loss: 0.7523 - val_acc: 0.5367\n",
      "Epoch 8/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4638 - acc: 0.7881 - val_loss: 0.4155 - val_acc: 0.8400\n",
      "Epoch 9/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4497 - acc: 0.7867 - val_loss: 0.3376 - val_acc: 0.8433\n",
      "Epoch 10/10\n",
      "2700/2700 [==============================] - 5s 2ms/step - loss: 0.4437 - acc: 0.7944 - val_loss: 0.5701 - val_acc: 0.6967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a26752c88>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(LSTM(64, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(LSTM(64, return_sequences=False))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(2))\n",
    "model3.add(Activation('softmax'))\n",
    "\n",
    "model3.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model3.fit(X_train, y_train, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4213/4213 [==============================] - 2s 436us/step\n"
     ]
    }
   ],
   "source": [
    "score3 = model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds3 = model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_classes = preds3.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.73      0.68      1734\n",
      "          1       0.79      0.70      0.74      2479\n",
      "\n",
      "avg / total       0.72      0.71      0.72      4213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_classes, y_true=y_test_ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.6827772585960287\n",
      "Test accuracy: 0.6536909565630192\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score3[0])\n",
    "print('Test accuracy:', score3[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "2700/2700 [==============================] - 428s 159ms/step - loss: 1.3255 - acc: 0.5022 - val_loss: 1.6390 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2700/2700 [==============================] - 426s 158ms/step - loss: 0.7775 - acc: 0.5063 - val_loss: 0.7950 - val_acc: 0.0567\n",
      "Epoch 3/10\n",
      "2700/2700 [==============================] - 428s 159ms/step - loss: 0.7383 - acc: 0.5289 - val_loss: 1.5578 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "2700/2700 [==============================] - 431s 160ms/step - loss: 0.7879 - acc: 0.5048 - val_loss: 1.3579 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "2700/2700 [==============================] - 434s 161ms/step - loss: 0.8504 - acc: 0.5019 - val_loss: 0.5839 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "2700/2700 [==============================] - 433s 160ms/step - loss: 0.7851 - acc: 0.5096 - val_loss: 0.2932 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "2700/2700 [==============================] - 430s 159ms/step - loss: 0.7494 - acc: 0.5474 - val_loss: 0.3931 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "2700/2700 [==============================] - 427s 158ms/step - loss: 0.7294 - acc: 0.5363 - val_loss: 0.8230 - val_acc: 0.4967\n",
      "Epoch 9/10\n",
      "2700/2700 [==============================] - 427s 158ms/step - loss: 0.7181 - acc: 0.5722 - val_loss: 1.1501 - val_acc: 0.5100\n",
      "Epoch 10/10\n",
      "2700/2700 [==============================] - 426s 158ms/step - loss: 0.7171 - acc: 0.5633 - val_loss: 1.0091 - val_acc: 0.6267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22a311ddba8>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(LSTM(1024, return_sequences=True, input_shape=(maxlen, len(chars)))) #меняем число нейронов\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(LSTM(1024, return_sequences=False))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(2))\n",
    "model4.add(Activation('softmax'))\n",
    "\n",
    "model4.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model4.fit(X_train, y_train, batch_size=batch_size, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4213/4213 [==============================] - 189s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "score4 = model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9711225434886626\n",
      "Test accuracy: 0.5988606693567529\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score4[0])\n",
    "print('Test accuracy:', score4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds4 = model4.predict(X_test)\n",
    "y_classes = preds4.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.73      0.66      1734\n",
      "          1       0.77      0.66      0.71      2479\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=y_classes, y_true=y_test_ar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять почти ничего не изменилось. В целом байесовскй классификатор показал более точные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
